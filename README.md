# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
+ The dataset on this project contains data about direct marketing campaigns through a phone call of a banking institution. This project aims to predict if the client will subscribe `(yes/no)` to a term deposit `(y variable)`.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

## Scikit-learn Pipeline
+ After initializing the workspace and creating the compute target for training the model, the first step in the project is creating a `TabularDataset` from a CSV file downloaded from a public web URL using `TabularDatasetFactory` class.

+ The data was then *prepared*,*cleansed*, and *split* using the pre-configured training script **`(train.py)`**. The data is sorted categorically hence *one-hot encoding* is used in cleaning the data executed inside the `clean_data` function in the `train.py` script. It creates a new binary column that indicated the existence of each possible value from the original data. The dataset was split into a *train (2/3)* and a *test (1/3)* dataset.

+ The classification algorithm used is **logistic regression**. It is used to estimate discrete value (yes/no, 0 or 1, true/false) based on a given set of independent variables. It is a special case of linear regression where the outcome variable is categorical. The log of odds is the dependent variable, that is, it predicts the probability of occurrence of an event by fitting data to a logic function.

+ Next, **SKLearn estimator** was constructed. This estimator will provide a simple way of deploying the training job on the compute target. 

+ Using the Python SDK we kick-off the hyperparameter tuning run and chose **Random Sampling Parameter** strategy.  Ranges for the *inverse of the regularization strength* and *maximum number of iterations to converge* are provided. Then **Bandit Policy** was used to define the early termination policy to terminate the jobs that are not performing well.

+ **HyperDriveConfig** was then configured and `Accuracy` was specified as the primary metric. The maximum number of concurrent jobs is set to 4 which is equal to the number of nodes in the compute cluster. 

+ Lastly, the hyperdrive run was submitted to the experiment and the model from the *best run* was saved.

**What are the benefits of the parameter sampler you chose?**
+ **Hyperparameters** are adjustable parameters you choose for model training that guide the training process. **Random Parameter Sampling** is used to define random sampling over a hyperparameter search space.
+ In this hyperparameter tuning, **Random Parameter Sampling** is used to try different configuration sets in the distribution of *continuous hyperparamaters `(C and max_iter)`* that will maximize the *primary metric `(Accuracy)`*.

**What are the benefits of the early stopping policy you chose?**
+ The **Bandit Policy** basically states to check the job *for every 2 iterations*. If the primary metric (accuracy) falls outside the *top 10 % range*, Azure ML will **end** the job. This saves consuming a lof of computational resources and from continuing to explore hyperparameters that don't show promise of helping reach our target metric.
## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
